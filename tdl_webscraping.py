# -*- coding: utf-8 -*-
"""TDL_webscraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P0Exmw0a4GPfgrrktyKneHe9nl4euIIX
"""

from bs4 import BeautifulSoup
import pandas as pd
import requests
from sklearn.model_selection import train_test_split


def scrape_website(page_number):
    authors=[]
    dates=[]
    statements=[]
    sources=[]
    targets=[]

    page_num=str(page_number)
    URL='https://www.politifact.com/factchecks/list/?page='+page_num

    webpage=requests.get(URL)
    soup=BeautifulSoup(webpage.text,'html.parser')
    statement_footer=soup.find_all('footer',attrs={'class':'m-statement__footer'})
    statement_quote=soup.find_all('div',attrs={'class':'m-statement__quote'})
    statement_meta=soup.find_all('div',attrs={'class':'m-statement__meta'})
    target=soup.find_all('div',attrs={'class':'m-statement__meter'})

    for i in range(len(statement_footer)):
        link1=statement_footer[i].text.strip()
        name_and_date=link1.split()
        first_name=name_and_date[1]
        last_name=name_and_date[2]
        full_name=first_name+' '+last_name
        month=name_and_date[4]
        day=name_and_date[5]
        year=name_and_date[6]
        date=month+' '+day+' '+year
        dates.append(date)
        authors.append(full_name)

        link2=statement_quote[i].find('a').text.strip()
        statements.append(link2)

        link3=statement_meta[i].find('a').text.strip()
        sources.append(link3)

        link4=target[i].find('div',attrs={'class':'c-image'}).find('img').get('alt')
        targets.append(link4)

    data=pd.DataFrame({
        'author':authors,
        'statement':statements,
        'source':sources,
        'date':dates,
        'target':targets
    })

    return data

data = pd.DataFrame(columns=['author','statement','source','date','target'])

for i in range(1, 100):  # Scrape pages 1 and 2
    scraped_data = scrape_website(i)
    data = pd.concat([data, scraped_data], ignore_index=True)

data.to_csv('political_fact_checker.csv', index=False)

